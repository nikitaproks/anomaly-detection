{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CNN Aproach with scalogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ssqueezepy import cwt, icwt\n",
    "from ssqueezepy.visuals import plot, imshow\n",
    "from scipy import signal\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.set_printoptions(formatter={'all':lambda x: str(x)})\n",
    "pd.options.display.float_format = '{:.10f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "class Plot:\n",
    "    def __init__(self, df,  title):\n",
    "        self.df = df\n",
    "        self.fig = plt.figure(figsize =(25, 8)) \n",
    "        self.fig.suptitle(title) \n",
    "\n",
    "        self.ax = self.fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "        max_xticks = 10\n",
    "        xloc = plt.MaxNLocator(max_xticks)\n",
    "        self.ax.xaxis.set_major_locator(xloc)\n",
    "    def chart(self, column_names, anomalies = False, vertical = False):\n",
    "        for column_name in column_names:\n",
    "            self.ax.plot(self.df.index, self.df[column_name], label = column_name)\n",
    "            if anomalies:\n",
    "                self.ax.plot(self.df[self.df[\"Anomaly\"]==True].index, self.df[column_name][self.df[\"Anomaly\"]==True], marker = 'o', ms = 3, mec = 'r', mfc = 'r', linestyle = \"None\", label=\"Anomalies\")\n",
    "        if vertical:\n",
    "            for i in range(0, len(self.df)-1): \n",
    "                if self.df[\"Anomaly\"].iloc[i]:\n",
    "                    self.ax.axvline(x = self.df.index[i], color = 'r', linestyle = 'dashed', linewidth=0.05)\n",
    "        self.fig.autofmt_xdate(rotation=15)\n",
    "        self.ax.legend()\n",
    "    def show(self): \n",
    "        plt.show()\n",
    "        \n",
    "    def save(self, image_path):\n",
    "        path = f'../images/{image_path}.png'\n",
    "        self.fig.savefig(path, facecolor='white', transparent=False)\n",
    "        plt.close(self.fig)\n",
    "\n",
    "def create_save_sca(X, Y, step, row_length, parameter):\n",
    "    for i in tqdm(range(0, len(X)), desc=f\"Set creation progress...\"): \n",
    "        fig, axs = plt.subplots(2)\n",
    "        fig.suptitle('Chart and Scalogram')      \n",
    "       \n",
    "        Wx, scales = cwt(X[i], 'morlet')\n",
    "        imshow(Wx,ticks=0, borders=0, abs=1, ax=axs[1], show=0)\n",
    "        axs[0].plot(X[i])\n",
    "        \n",
    "        dir_path = f'Scalograms/S{step}L{row_length}/'\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        fig.savefig(dir_path + f'{i+1}_sca.png', facecolor='white', transparent=False)\n",
    "        plt.close(fig)\n",
    "        \n",
    "# Finding anomalies\n",
    "def find_column_anomaly(df, column):\n",
    "    anomaly = ((df[column] > df[column].mean()+10) | (df[column] < df[column].mean()-10))\n",
    "    #anomaly[anomaly==0] = -1\n",
    "    return anomaly\n",
    "\n",
    "\n",
    "def find_anomalies_std(df, columns):\n",
    "    anomalies = []\n",
    "    for column in columns:\n",
    "        anomalies_array = find_column_anomaly(df, column)\n",
    "        anomalies.append(anomalies_array)\n",
    "    df_anomalies = pd.DataFrame(anomalies).transpose().astype(int).sum(axis=1)\n",
    "    df[\"Anomaly\"] = df_anomalies>=0.75*len(columns)\n",
    "    return df\n",
    "\n",
    "# Data processing\n",
    "def get_sets(df, columns, step, row_length):\n",
    "    rows_num = int(len(df)/step - (row_length/step-1))\n",
    "    \n",
    "    values = df[columns].values\n",
    "    anomalies = df['Anomaly'].values\n",
    " \n",
    "    X = np.zeros((rows_num, row_length,len(columns)))\n",
    "    Y = np.zeros((rows_num, 1))\n",
    "    \n",
    "    for i in range(0, rows_num):\n",
    "        first_element = step*i\n",
    "        last_element = step*i+row_length\n",
    "        X[i] = values[first_element:last_element]\n",
    "        Y[i] = anomalies[first_element:last_element].sum()\n",
    "    Y = np.where(Y > 0, 1, 0)\n",
    "    return X, Y\n",
    "\n",
    "def wavelet_transformation(X, columns, values_type=\"Complex\"):\n",
    "    Wx_test, scales_test  = cwt(X[0][:,0], 'morlet')\n",
    "    X_shape = Wx_test.shape\n",
    "    scales_shape = scales_test.shape\n",
    "    data = np.zeros((len(X), X_shape[0], X_shape[1], len(columns)*2))\n",
    "    counter = 0\n",
    "    for row in tqdm(X, desc=f\"Data creation progress...\"):\n",
    "        images = []\n",
    "        for i in range(0, len(row[0])):\n",
    "            Wx, scales = cwt(row[:, i], 'morlet')\n",
    "            real = np.reshape(Wx.real, (Wx.shape[0], Wx.shape[1], 1))\n",
    "            imag = np.reshape(Wx.imag, (Wx.shape[0], Wx.shape[1], 1))\n",
    "            image = np.concatenate([real, imag], axis=2)\n",
    "            images.append(image)\n",
    "        data[counter] = np.concatenate(images, axis=2)\n",
    "        counter +=1\n",
    "    return data\n",
    "\n",
    "\n",
    "# Filw management\n",
    "def create_directory(dataset_name):\n",
    "    dir_path = f'datasets/{dataset_name}/'\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/thm/processed_thermal_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating gradual increase\n",
    "max_increase = 100\n",
    "incline_temp = np.linspace(30, max_increase, len(df))\n",
    "df[\"Incline_temp\"] = incline_temp\n",
    "df[\"B1_inclined\"] = df[\"Incline_temp\"] + df[\"B1_temp\"]\n",
    "\n",
    "# Creating SIN function\n",
    "periods = 20\n",
    "max_amplitude = 20\n",
    "time        = np.linspace(0, periods*4, len(df));\n",
    "amplitude   = np.sin(time)*max_amplitude\n",
    "df[\"B1_sin\"] = amplitude + df[\"B1_temp\"]\n",
    "\n",
    "# Creating SIN + gradual increase\n",
    "df[\"B1_inclined_sin\"] = df[\"B1_temp\"] + df[\"Incline_temp\"] + amplitude\n",
    "\n",
    "# Creating Sigmoid\n",
    "increase = 200\n",
    "increase_gradient = 100\n",
    "x = np.linspace(-increase_gradient, increase_gradient, len(df))\n",
    "sigmoid = 1/(1 + np.exp(-x+40))*increase\n",
    "df[\"B1_sigmoid\"] = df[\"B1_temp\"] + sigmoid \n",
    "\n",
    "increase = -100\n",
    "increase_gradient = 50\n",
    "x = np.linspace(-increase_gradient, increase_gradient, len(df))\n",
    "sigmoid = 1/(1 + np.exp(-x+40))*increase\n",
    "df[\"B2_inclined\"] = df[\"B2_temp\"] + incline_temp \n",
    "df[\"MB_sin\"] = df[\"MB_temp\"] - amplitude \n",
    "df[\"BMB_sigmoid\"] = df[\"BMB_temp\"] - sigmoid\n",
    "df[\"B2_sigmoid\"] = df[\"B2_temp\"] + sigmoid \n",
    "df[\"MB_sigmoid\"] = df[\"MB_temp\"] + sigmoid \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for scalogram creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data creation progress...: 100%|██████████| 4999/4999 [03:16<00:00, 25.44it/s]\n"
     ]
    }
   ],
   "source": [
    "step = 20\n",
    "row_length = 40\n",
    "test_size = 0.6\n",
    "columns = [\"B1_sigmoid\", \"B2_sigmoid\",\"MB_sigmoid\", \"BMB_sigmoid\"]\n",
    "\n",
    "df = find_anomalies_std(df, [\"B1_temp\", \"B2_temp\",\"MB_temp\", \"BMB_temp\"])\n",
    "df_new = df.iloc[-100000:,:]\n",
    "\n",
    "X, Y =  get_sets(df_new, columns, step, row_length)\n",
    "\n",
    "\n",
    "data = wavelet_transformation(X, columns)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, Y, test_size=test_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing directories and saving scalograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save done\n"
     ]
    }
   ],
   "source": [
    "dataset_name = f'{\"&\".join(columns)}-{row_length}L{step}S{int(test_size*100)}T'\n",
    "create_directory(dataset_name)\n",
    "\n",
    "np.save(f'datasets/{dataset_name}/X.npy', X)\n",
    "np.save(f'datasets/{dataset_name}/original_data.npy', df_new[columns+[\"Anomaly\"]].values)\n",
    "np.save(f'datasets/{dataset_name}/x_train.npy', x_train)\n",
    "np.save(f'datasets/{dataset_name}/y_train.npy', y_train)\n",
    "np.save(f'datasets/{dataset_name}/x_test.npy', x_test)\n",
    "np.save(f'datasets/{dataset_name}/y_test.npy', y_test)\n",
    "\n",
    "print(\"Save done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
