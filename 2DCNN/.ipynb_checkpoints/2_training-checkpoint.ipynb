{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this file the model is set and the processed data is used to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if does not exist\n",
    "def create_directory(directory_name):\n",
    "    dir_path = f'{directory_name}/'\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "        self.model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "        self.model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "        self.model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(units=128, activation='relu'))\n",
    "        self.model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the data to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "1) B1_temp-40L20S60T\n",
      "\n",
      "\n",
      "Choose dataset number: 1\n"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "create_directory('models/')\n",
    "\n",
    "# Get existing models\n",
    "models = os.listdir(f'models/')\n",
    "\n",
    "# Get existing datasets\n",
    "datasets = os.listdir(f'datasets/')\n",
    "datasets.sort()\n",
    "datasets.pop(0)\n",
    "\n",
    "# Printing available datasets\n",
    "print(\"Available datasets:\")\n",
    "for i, dataset in enumerate(datasets):\n",
    "    if f'{dataset}' in models:\n",
    "        print(f'{i}) {dataset} - Model Exists!')\n",
    "    else:\n",
    "        print(f'{i}) {dataset}')\n",
    "\n",
    "# Prompting the input from user\n",
    "chosen_dataset = int(input(\"Choose dataset number: \"))\n",
    "\n",
    "# Setting the chosen dataset\n",
    "dataset_name = datasets[chosen_dataset-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the chosen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(f'datasets/{dataset_name}/x_train.npy')\n",
    "y_train = np.load(f'datasets/{dataset_name}/y_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 16\n",
    "validation_split = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train[0].shape\n",
    "cnn = CNN(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 16s 164ms/step - loss: 0.0570 - accuracy: 0.9813 - val_loss: 2.2040e-11 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 15s 160ms/step - loss: 1.8005e-11 - accuracy: 1.0000 - val_loss: 2.1828e-11 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 15s 160ms/step - loss: 1.7986e-11 - accuracy: 1.0000 - val_loss: 2.1828e-11 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 15s 164ms/step - loss: 1.7985e-11 - accuracy: 1.0000 - val_loss: 2.1828e-11 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 16s 173ms/step - loss: 1.7985e-11 - accuracy: 1.0000 - val_loss: 2.1827e-11 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 16s 173ms/step - loss: 1.7985e-11 - accuracy: 1.0000 - val_loss: 2.1827e-11 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 16s 174ms/step - loss: 1.7984e-11 - accuracy: 1.0000 - val_loss: 2.1826e-11 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 16s 174ms/step - loss: 1.7984e-11 - accuracy: 1.0000 - val_loss: 2.1826e-11 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 18s 190ms/step - loss: 1.7983e-11 - accuracy: 1.0000 - val_loss: 2.1825e-11 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 17s 178ms/step - loss: 1.7982e-11 - accuracy: 1.0000 - val_loss: 2.1824e-11 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3a591d700>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/B1_temp-40L20S60T/assets\n"
     ]
    }
   ],
   "source": [
    "path = f\"models/{dataset_name}\"\n",
    "cnn.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
