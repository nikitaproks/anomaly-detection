{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D CNN Aproach with scalogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "np.set_printoptions(formatter={'all':lambda x: str(x)})\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "        self.model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "        self.model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "        self.model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(units=128, activation='relu'))\n",
    "        self.model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"/Users/mykytaprokayev/Documents/TUM/Master Thesis/Presentation_images/2dcnn_structure.png\"\n",
    "plot_model(cnn.model,to_file=file,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      "1) B1_sigmoid&B2_sigmoid&MB_sigmoid&BMB_sigmoid-40L20S60T\n",
      "2) B1_sigmoid&B2_temp&MB_temp&BMB_temp-40L20S60T - Model Exists!\n",
      "3) B1_sigmoid-20L10S60T - Model Exists!\n",
      "4) B1_sigmoid-40L10S60T - Model Exists!\n",
      "5) B1_sigmoid-40L20S60T - Model Exists!\n",
      "6) B1_sigmoid-40L40S60T - Model Exists!\n",
      "7) B1_sigmoid-80L40S60T - Model Exists!\n",
      "8) B1_sigmoid-80L80S60T - Model Exists!\n",
      "9) B1_temp&B2_temp&MB_temp&BMB_temp-40L20S60T - Model Exists!\n",
      "10) B1_temp&B2_temp&MB_temp&BMB_temp-80L80S60T\n",
      "11) B1_temp-40L20S60T - Model Exists!\n",
      "12) BCR_1_Power-40L20S60T\n",
      "13) MB_sigmoid&BMB_sigmoid&B1_sigmoid&B2_sigmoid-40L20S60T\n",
      "14) MB_sin&BMB_sigmoid&B1_sigmoid&B2_inclined-40L20S60T\n",
      "15) MB_temp&BMB_temp&B1_sigmoid&B2_temp-40L20S60T\n",
      "16) MB_temp&BMB_temp&B1_temp&B2_temp-10L10S60T\n",
      "17) MB_temp&BMB_temp&B1_temp&B2_temp-40L20S60T\n",
      "18) MB_temp&BMB_temp&B1_temp&B2_temp-5L5S60T\n",
      "19) MB_temp-20L20S60T\n",
      "20) MB_temp-40L10S60T\n",
      "21) MB_temp-40L20S60T\n",
      "22) MB_temp-40L40S60T\n",
      "23) MB_temp-40L5S60T\n",
      "24) PDM Power ADCS 5V 1&PDM Power ADCS 3.3V 1-40L20S60T\n",
      "25) PDM Power PL 5V&PDM Power PL 3.3V&PDM Power ADCS 5V 1&PDM Power ADCS 5V 2&PDM Power ADCS 3.3V 1&PDM Power ADCS 3.3V 2-40L20S60T\n",
      "\n",
      "\n",
      "Choose dataset number: 1\n"
     ]
    }
   ],
   "source": [
    "datasets = os.listdir(f'datasets/')\n",
    "datasets.sort()\n",
    "datasets.pop(0)\n",
    "models = os.listdir(f'Models/')\n",
    "\n",
    "print(\"Available datasets:\")\n",
    "counter = 1\n",
    "for dataset in datasets:\n",
    "    if f'{dataset}' in models:\n",
    "        print(f'{counter}) {dataset} - Model Exists!')\n",
    "    else:\n",
    "        print(f'{counter}) {dataset}')\n",
    "    counter += 1\n",
    "print(\"\\n\")     \n",
    "chosen_dataset = int(input(\"Choose dataset number: \"))\n",
    "dataset_name = datasets[chosen_dataset-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "94/94 [==============================] - 19s 190ms/step - loss: 0.2227 - accuracy: 0.9807 - val_loss: 1.0381e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "94/94 [==============================] - 16s 172ms/step - loss: 5.5699e-04 - accuracy: 1.0000 - val_loss: 7.9929e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "94/94 [==============================] - 15s 162ms/step - loss: 5.0819e-05 - accuracy: 1.0000 - val_loss: 3.3228e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "94/94 [==============================] - 15s 164ms/step - loss: 2.4678e-05 - accuracy: 1.0000 - val_loss: 1.9116e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "94/94 [==============================] - 16s 174ms/step - loss: 1.5354e-05 - accuracy: 1.0000 - val_loss: 1.2819e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "94/94 [==============================] - 17s 184ms/step - loss: 1.0697e-05 - accuracy: 1.0000 - val_loss: 9.3253e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "94/94 [==============================] - 16s 171ms/step - loss: 7.9726e-06 - accuracy: 1.0000 - val_loss: 7.1471e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "94/94 [==============================] - 16s 175ms/step - loss: 6.2324e-06 - accuracy: 1.0000 - val_loss: 5.6733e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "94/94 [==============================] - 16s 173ms/step - loss: 5.0257e-06 - accuracy: 1.0000 - val_loss: 4.6390e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "94/94 [==============================] - 16s 174ms/step - loss: 4.1482e-06 - accuracy: 1.0000 - val_loss: 3.8572e-06 - val_accuracy: 1.0000\n",
      "INFO:tensorflow:Assets written to: models/B1_sigmoid&B2_sigmoid&MB_sigmoid&BMB_sigmoid-40L20S60T/assets\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(f'datasets/{dataset_name}/x_train.npy')\n",
    "y_train = np.load(f'datasets/{dataset_name}/y_train.npy')\n",
    "\n",
    "input_shape = x_train[0].shape\n",
    "\n",
    "cnn = CNN(input_shape)\n",
    "cnn.model.fit(x_train, y_train, epochs=10, batch_size=16, validation_split=0.25)\n",
    "\n",
    "path = f\"models/{dataset_name}\"\n",
    "cnn.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
