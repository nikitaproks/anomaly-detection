{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from ssqueezepy import cwt, icwt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (<ipython-input-2-710794e01712>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-710794e01712>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    def __init__(self, check_freq: int, log_dir: str,\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq:\n",
    "    :param log_dir: Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: Verbosity level.\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, \n",
    "                 algorithm: str, column: str, obs_size: int,\n",
    "                ep_length: int, verbose: int = 1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, f'best_models/{algorithm}_models/{column}/OBS_{obs_size}/EL_{ep_length}/')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        self.test_number = 1\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        else:\n",
    "            folder_names = os.listdir(self.save_path)\n",
    "            for folder_name in folder_names:\n",
    "                number = folder_name.split(\".\")[0].split(\"_\")[-1]\n",
    "                if number.isdigit():\n",
    "                    number = int(number)\n",
    "                    if number >= self.test_number:\n",
    "                        self.test_number = number + 1\n",
    "                    \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "          # Retrieve training reward\n",
    "          x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "          if len(x) > 0:\n",
    "              # Mean training reward over the last 100 episodes\n",
    "              mean_reward = np.mean(y[-100:])\n",
    "              if self.verbose > 0:\n",
    "                print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\")\n",
    "\n",
    "              # New best model, you could save the agent here\n",
    "              if mean_reward > self.best_mean_reward:\n",
    "                  self.best_mean_reward = mean_reward\n",
    "                  # Example for saving best model\n",
    "                  if self.verbose > 0:\n",
    "                    print(f\"Saving new best model to {self.save_path}\")\n",
    "                  self.model.save(self.save_path+ f\"model_{self.test_number}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, df, columns, step, row_length):\n",
    "        self.rows_num = int(len(df)/step - (row_length/step-1))\n",
    "        self.step = step\n",
    "        self.row_length = row_length\n",
    "        self.columns = columns\n",
    "        self.df = df\n",
    "        self.X_num = np.zeros((self.rows_num, self.row_length,len(self.columns)))   \n",
    "        self.create_sets()\n",
    "        \n",
    "    def create_sets(self):\n",
    "        values = self.df[self.columns].values\n",
    "        for i in range(0, self.rows_num):\n",
    "            first_element = self.step*i\n",
    "            last_element = self.step*i+self.row_length\n",
    "            self.X_num[i] = values[first_element:last_element]\n",
    "\n",
    "    def create_wavelets(self):\n",
    "        X_shape  = cwt(self.X_num[0][:,0], 'morlet')[0].shape\n",
    "        self.X = np.zeros((len(self.X_num), X_shape[0], X_shape[1]))\n",
    "        counter = 0\n",
    "        for row in tqdm(self.X_num, desc=f\"Data creation progress...\"):\n",
    "            Wx, scales = cwt(row[:,0], 'morlet')\n",
    "            self.X[counter] = abs(Wx)\n",
    "            counter +=1\n",
    "    \n",
    "    def setup_directory(self):\n",
    "        dir_path = f'../datasets/{self.dataset_name}/'\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "    \n",
    "    def save(self):\n",
    "        self.dataset_name = f'{\"&\".join(self.columns)}-{self.row_length}L{self.step}S'\n",
    "        self.setup_directory()\n",
    "        np.save(f'../datasets/{self.dataset_name}/X.npy', self.X)\n",
    "        np.save(f'../datasets/{self.dataset_name}/original_data.npy', self.df[self.columns].values)\n",
    "\n",
    "        print(\"Saving done\")\n",
    "    \n",
    "# Visualisation\n",
    "class Plot:\n",
    "    def __init__(self, df,  title):\n",
    "        self.df = df\n",
    "        self.fig = plt.figure(figsize =(25, 8)) \n",
    "        self.fig.suptitle(title) \n",
    "\n",
    "        self.ax = self.fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "        max_xticks = 10\n",
    "        xloc = plt.MaxNLocator(max_xticks)\n",
    "        self.ax.xaxis.set_major_locator(xloc)\n",
    "    def chart(self, column_names, anomalies = False, vertical = False):\n",
    "        for column_name in column_names:\n",
    "            self.ax.plot(self.df.index, self.df[column_name], label = column_name)\n",
    "            if anomalies:\n",
    "                self.ax.plot(self.df[self.df[\"Anomaly\"]==True].index, self.df[column_name][self.df[\"Anomaly\"]==True], marker = 'o', ms = 3, mec = 'r', mfc = 'r', linestyle = \"None\", label=\"Anomalies\")\n",
    "        if vertical:\n",
    "            for i in range(0, len(self.df)-1): \n",
    "                if self.df[\"Anomaly\"].iloc[i]:\n",
    "                    self.ax.axvline(x = self.df.index[i], color = 'r', linestyle = 'dashed', linewidth=0.05)\n",
    "        self.fig.autofmt_xdate(rotation=15)\n",
    "        self.ax.legend()\n",
    "    def show(self): \n",
    "        plt.show()\n",
    "        \n",
    "    def save(self, path):\n",
    "        self.fig.savefig(path, facecolor='white', transparent=False)\n",
    "        plt.close(self.fig)\n",
    "        print(\"Saving finished\")\n",
    "\n",
    "\n",
    "def get_data(columns, step, row_length, datatype, filename):\n",
    "    dataset_name = f'{\"&\".join(columns)}-{row_length}L{step}S'\n",
    "    dir_path = f'../datasets/{dataset_name}/'\n",
    "    if not os.path.exists(dir_path):\n",
    "        df = pd.read_csv(f'../../data/{datatype}/{filename}')\n",
    "        data = Preprocessor(df, columns, step, row_length)\n",
    "        data.create_wavelets()\n",
    "        data.save()\n",
    "        \n",
    "    X = np.load(f'../datasets/{dataset_name}/X.npy')\n",
    "    original_data = np.load(f'../datasets/{dataset_name}/original_data.npy', allow_pickle=True)\n",
    "    return X, original_data\n",
    "\n",
    "# Finding anomalies\n",
    "def find_column_anomaly(df, column):\n",
    "    anomaly = ((df[column] > df[column].mean()+10) | (df[column] < df[column].mean()-10))\n",
    "    #anomaly[anomaly==0] = -1\n",
    "    return anomaly\n",
    "\n",
    "\n",
    "def find_anomalies(df, columns):\n",
    "    anomalies = []\n",
    "    for column in columns:\n",
    "        anomalies_array = find_column_anomaly(df, column)\n",
    "        anomalies.append(anomalies_array)\n",
    "    df_anomalies = pd.DataFrame(anomalies).transpose().astype(int).sum(axis=1)\n",
    "    df[\"Anomaly\"] = df_anomalies>=0.75*len(columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def reward_calculation(wavelet, timestep):\n",
    "    reward = 0\n",
    "    current_sum = wavelet[:, timestep].sum()\n",
    "    if timestep>0 and timestep < len(wavelet[0])-1:\n",
    "        prev_sum = wavelet[:, timestep-1].sum()\n",
    "        next_sum =  wavelet[:, timestep+1].sum()\n",
    "        reward -= (prev_sum + next_sum)\n",
    "        reward += 2*current_sum\n",
    "    return reward    \n",
    "\n",
    "def setup_directory(main_path):\n",
    "    test_number = 1\n",
    "    if not os.path.exists(main_path):\n",
    "        os.makedirs(main_path)\n",
    "    else:\n",
    "        folder_names = os.listdir(main_path)\n",
    "        for folder_name in folder_names:\n",
    "            number = int(folder_name.split(\"_\")[-1])\n",
    "            if number > test_number:\n",
    "                test_number = number\n",
    "                \n",
    "    directory_name = f\"Test_{test_number}/\"\n",
    "    directory_path = main_path+directory_name\n",
    "    os.makedirs(directory_path)\n",
    "    return directory_path\n",
    "\n",
    "def save_info(directory_path, episode_length, lookback, train_timesteps, predict_iter, columns):\n",
    "    with open(directory_path +'info.txt', 'w') as file:\n",
    "        info = [\n",
    "                f'episode_length={episode_length}\\n', \n",
    "                f'lookback={lookback}\\n', \n",
    "                f'train_timesteps={train_timesteps}\\n', \n",
    "                f'predict_iter={predict_iter}\\n',\n",
    "                f'columns={\",\".join(columns)}\\n'\n",
    "               ]\n",
    "\n",
    "        file.writelines(data for data in books)\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self, data = []):\n",
    "        if len(data)>0:\n",
    "            self.original_max = max([abs(val) for val in data])\n",
    "    def normalize(self, data):\n",
    "        self.original_max = max([abs(val) for val in data])\n",
    "        normalized_data = [float(val)/self.original_max  for val in data]\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        return normalized_data\n",
    "    \n",
    "    def denormalize(self, normalized_data):\n",
    "        data = [float(val)*self.original_max  for val in normalized_data]\n",
    "        data = np.array(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
