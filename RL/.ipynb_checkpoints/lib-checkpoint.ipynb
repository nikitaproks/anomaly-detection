{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOnBestTrainingRewardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback for saving a model (the check is done every ``check_freq`` steps)\n",
    "    based on the training reward (in practice, we recommend using ``EvalCallback``).\n",
    "\n",
    "    :param check_freq:\n",
    "    :param log_dir: Path to the folder where the model will be saved.\n",
    "      It must contains the file created by the ``Monitor`` wrapper.\n",
    "    :param verbose: Verbosity level.\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int, log_dir: str, \n",
    "                 algorithm: str, column: str, obs_size: int,\n",
    "                ep_length: int, verbose: int = 1):\n",
    "        super(SaveOnBestTrainingRewardCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.save_path = os.path.join(log_dir, f'best_models/{algorithm}_models/{column}/OBS_{obs_size}/EL_{ep_length}/')\n",
    "        self.best_mean_reward = -np.inf\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        self.test_number = 1\n",
    "        if not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "        else:\n",
    "            folder_names = os.listdir(self.save_path)\n",
    "            for folder_name in folder_names:\n",
    "                number = folder_name.split(\".\")[0].split(\"_\")[-1]\n",
    "                if number.isdigit():\n",
    "                    number = int(number)\n",
    "                    if number >= self.test_number:\n",
    "                        self.test_number = number + 1\n",
    "                    \n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "\n",
    "          # Retrieve training reward\n",
    "          x, y = ts2xy(load_results(self.log_dir), 'timesteps')\n",
    "          if len(x) > 0:\n",
    "              # Mean training reward over the last 100 episodes\n",
    "              mean_reward = np.mean(y[-100:])\n",
    "              if self.verbose > 0:\n",
    "                print(f\"Num timesteps: {self.num_timesteps}\")\n",
    "                print(f\"Best mean reward: {self.best_mean_reward:.2f} - Last mean reward per episode: {mean_reward:.2f}\")\n",
    "\n",
    "              # New best model, you could save the agent here\n",
    "              if mean_reward > self.best_mean_reward:\n",
    "                  self.best_mean_reward = mean_reward\n",
    "                  # Example for saving best model\n",
    "                  if self.verbose > 0:\n",
    "                    print(f\"Saving new best model to {self.save_path}\")\n",
    "                  self.model.save(self.save_path+ f\"model_{self.test_number}\")\n",
    "\n",
    "        return True\n",
    "    \n",
    "class Normalizer:\n",
    "    \"\"\"\n",
    "    Normalizes and denormalizes the data. \n",
    "    All positive values are between 0 and 1.\n",
    "    All negative values are between -1 and 0.\n",
    "    \"\"\"\n",
    "    def __init__(self, data = []):\n",
    "        if len(data)>0:\n",
    "            self.original_max = max([abs(val) for val in data])\n",
    "    def normalize(self, data):\n",
    "        self.original_max = max([abs(val) for val in data])\n",
    "        normalized_data = [float(val)/self.original_max  for val in data]\n",
    "        normalized_data = np.array(normalized_data)\n",
    "        return normalized_data\n",
    "    \n",
    "    def denormalize(self, normalized_data):\n",
    "        data = [float(val)*self.original_max  for val in normalized_data]\n",
    "        data = np.array(data)\n",
    "        return data\n",
    "\n",
    "\n",
    "# Finding anomalies of a single column by creating a threshold (used for reference)\n",
    "def find_column_anomaly(df, column):\n",
    "    anomaly = ((df[column] > df[column].mean()+10) | (df[column] < df[column].mean()-10))\n",
    "    #anomaly[anomaly==0] = -1\n",
    "    return anomaly\n",
    "\n",
    "# Finding anomalies of a multiple columns by creating a threshold (used for reference)\n",
    "def find_anomalies(df, columns):\n",
    "    anomalies = []\n",
    "    for column in columns:\n",
    "        anomalies_array = find_column_anomaly(df, column)\n",
    "        anomalies.append(anomalies_array)\n",
    "    df_anomalies = pd.DataFrame(anomalies).transpose().astype(int).sum(axis=1)\n",
    "    df[\"Anomaly_ref\"] = df_anomalies>=0.75*len(columns)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
